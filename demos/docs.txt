run /Eureka/demos/eureka.py

14 in eureka.py to:
/Eureka/eureka/S3_data_reduction/s3_reduce.py

88 in s3_reduce.py to: 
/Eureka/eureka/lib/readECF.py

123 in readECF.py to:
/Eureka/demos/S3_wasp43b.ecf

130 in readECF.py reads in the lines of S3_wasp43b.ecf
lines are saved into cleanlines variable
lines then saved into params variable

89 in s3_reduce.py: params set in ecf file (like inst) are stored in Event object 
(eg.: ev.inst)

oida! 92 in s3_reduce.py: import ev.inst as inst
nircam.py is being imported

97 in s3_reduce.py creates logfile using lib/logedit.py

103 in s3_reduce.py: checks the files in the data directory (set in ecf):
store the names of the fit files ending in *calints.fits (=ev.suffix set in ecf) into ev.segment_list

105 in s3_reduce.py: has "sort_nicely". I commented it out. Probably sorts by *segxxx*

107 in s3_reduce.py: writes into log how many files ending with *calints.fits were found

117 in s3_reduce.py: uses "inst.read" and we jump into nircam.py -> def read

32 in nircam.py read fits file:

    intstart    = mhdr['INTSTART']
    intend      = mhdr['INTEND']

NINTS   =                 1287 / Number of integrations in exposure             
INTSTART=                    1 / Starting integration number in this segment    
INTEND  =                   64 / Ending integration number in this segment      
NGROUPS =                   19 / Number of groups in integration



extensions:
hdu 0:  PRIMARY
hdu 1:  SCI , shape:  (64, 64, 2048)     MJy/sr
hdu 2:  ERR , shape:  (64, 64, 2048)     MJy/sr
hdu 3:  DQ , shape:  (64, 64, 2048)
hdu 4:  WAVELENGTH , shape:  (64, 2048)
hdu 5:  AREA , shape:  (64, 64, 2048)
hdu 6:  VAR_POISSON , shape:  (64, 64, 2048)
hdu 7:  VAR_RNOISE , shape:  (64, 64, 2048)
hdu 8:  VAR_FLAT , shape:  (64, 64, 2048)
hdu 9:  INT_TIMES , shape:  (1287,)
hdu 10:  ASDF , shape:  (1,)


    data    = hdulist['SCI',1].data
    err     = hdulist['ERR',1].data
    dq      = hdulist['DQ',1].data
    wave    = hdulist['WAVELENGTH',1].data
    v0      = hdulist['VAR_RNOISE',1].data
    int_times = hdulist['INT_TIMES',1].data[intstart-1:intend]


finally return master and science headers and data, err, dq, wave, v0, int_times

119 in s3_reduce.py: n_int, ny, nx = data.shape

121 in s3_reduce.py:

         # Locate science image
        xref_sci = shdr['XREF_SCI']
        yref_sci = shdr['YREF_SCI']

125 in s3_reduce.py is weird: 
int_times looks like:
[( 1, 59694.10251112, 59694.10254857, 59694.10258602, 59694.10251112, 59694.10254857, 59694.10258602), 
( 2, 59694.10258996, 59694.10262741, 59694.10266486, 59694.10258996, 59694.10262741, 59694.10266486),...]

using the following form:
('integration_number', 'int_start_MJD_UTC', 'int_mid_MJD_UTC', 'int_end_MJD_UTC', 'int_start_BJD_TDB', 'int_mid_BJD_TDB', 'int_end_BJD_TDB')

MJD_UTC and BJD_TDB is the same though -> Barycentric correction isnt being done yet.



ecf:
# Subarray region of interest
ywindow     [5,64]
xwindow     [100,1700]


127 in s3_reduce.py: 
        # Trim data to subarray region of interest
        subdata  = data[:,ev.ywindow[0]:ev.ywindow[1],ev.xwindow[0]:ev.xwindow[1]]

data is in 'MJy/sr  ':
BUNIT   = 'MJy/sr  '           / physical units of the array values 


143 in s3_reduce.py: 
background outlier rejection
jump into nircam.py line 57:

bgdata1 = data[:,  :y1] ...  data for lower background strip for 0 to y1=14

bgdata2 has upper 5 lines

bg_thresh = [5, 5]

jump into /Eureka/eureka/S3_data_reduction/sigrej.py line 115




ival has dimensions (2,2,14,1600)

nsig=2 -> we do sigma rejection twice over time
-> look at every background pixel and reject 5 sigma outliers in TIME

sigrej.py 153: calculates for every single background pixel the median flux level over all 64 integrations
stores that in ival[0, iter, j, i]


final mask:
(data >= (ival[0,iter] - sigma[iter] * ival[1,iter])) &
              (data <= (ival[0,iter] + sigma[iter] * ival[1,iter])) 



ival[0,iter] has median value of background data pixels over time
eg.: median value of pixel (0,0) over all 64 int, median value of pixel (0,1) over all 64 int, etc. 

sigma[iter] = 5 defined in ecf

ival[1,iter] has median err value in the background slice over ALL times. Is a number


AGAIN 5 sigma clipping with iter=1

reminder of sigrej.py is skipped


back to nircam.py line 66 and jump back to /sigrej.py line 115 to do the same for upper background slice

back to 147 in s3_reduce.py
line 160 jumps to nircam.py line 74
then jumo into /Eureka/eureka/S3_data_reduction/optspex.py line 24



we transpose the data (requiremnt in optspex that x is the spatial direction and y is the wavelength direction)


check if there is a 5 sigma outlier in the spatial direction

line 76: Fit along spatial direction with a polynomial of degree 'deg'
deg is set in ecf. it's 0 
So it's basically np.mean(dataslice), so mean of the first integration of the first background column 
where dataslice is data[0,j,goodxvals]
where goodxvals=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 55 56 57 58] are the background pixels in the spatial direction

residuals = dataslice - model
calculates the Mean Absolute Deviation of the residuals 
stdres  = np.mean(np.abs(np.ediff1d(residuals)))
stdevs    = np.abs(residuals) / stdres
->calculated the sigma outlier value. Check the highest sigma value
if there is no 5 sigma outlier, we are done and have the column background value for this particular column and exposure.
if there is a 5 sigma outlier, we remove this background pixel and recalculate the simga values too see if there's still a 5 sigma outlier


Repeat for every column

derotate again in line 127
jump back to nircam.py line 76 and immediately to s3_reduce.py line 150 

do the same for all 64 integrations


s3_reduce.py line 179 
subdata    -= subbg


# Extract standard spectrum and its variance
        stdspec     = np.sum(subdata, axis=1)
        stdvar      = np.sum(suberr**2, axis=1)
shape : (64,1600)



DO ALL OF THAT AGAIN FOR THE NEXT FITS FILE


s3_reduce.py line 242
saveevent -> goes into /Eureka/eureka/lib/manageevent.py
 













# 1.  Read in all data frames and header info from Stage 2 data products
Done



# 2.  Record JD and other relevant header information
Done
added ra, dec for barycentric correction



# 3.  Apply light-time correction (if necessary)
Done now
Added /Eureka/eureka/lib/barycorr.py
and /Eureka/eureka/lib/suntimecorr.py

this calculation might be moved to the very end so that functions are only called once



# 4.  Calculate trace and 1D+2D wavelength solutions (if necessary)
created /Eureka/eureka/S3_data_reduction/trace.py
taken from /Eureka/eureka/S3_data_reduction/wfc3_scan.py



# 5.  Make flats, apply flat field correction (Stage 2)
created /Eureka/eureka/S3_data_reduction/flats.py
taken from /Eureka/eureka/S3_data_reduction/wfc3_scan.py



# 6.  Manually mask regions
Partially done with new Kevin push


# 7.  Compute difference frames OR slopes (Stage 1)
# 8.  Perform outlier rejection of BG region
Done

# 9.  Background subtraction
Donw

# 10. Compute 2D drift, apply rough (integer-pixel) correction
# 11. Full-frame outlier rejection for time-series stack of NDRs
# 12. Apply sub-pixel 2D drift correction
# 13. Extract spectrum through summation
Done

# 14. Compute median frame
Done


# 15. Optimal spectral extraction
done with new Kevin push


# 16. Save Stage 3 data products
Done now
Big data files though!


# 17. Produce plots
Done














